{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Unlearning"
      ],
      "metadata": {
        "id": "Z2-HJGN2ikUy"
      }
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "hbRiNSHNinCB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#getting the necessary imports\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "import torch.backends.cudnn as cudnn\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import os\n",
        "import argparse\n"
      ],
      "metadata": {
        "id": "9TzOUBtUg71Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lhwRBvd12I1r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb1c4517-c33d-4c12-e966-a84b039a9af3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "cuda\n",
            "==> Preparing data..\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./data/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 170498071/170498071 [00:05<00:00, 29967729.63it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ./data/cifar-10-python.tar.gz to ./data\n",
            "Files already downloaded and verified\n"
          ]
        }
      ],
      "source": [
        "#basic resnet architecture\n",
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ResNet(nn.Module):\n",
        "    def __init__(self, block, num_blocks, num_classes=10):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_planes = 64\n",
        "\n",
        "        self.conv1 = nn.Conv2d(3, 64, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(64)\n",
        "        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n",
        "        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n",
        "        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n",
        "        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n",
        "        self.linear = nn.Linear(512*block.expansion, num_classes)\n",
        "\n",
        "    def _make_layer(self, block, planes, num_blocks, stride):\n",
        "        strides = [stride] + [1]*(num_blocks-1)\n",
        "        layers = []\n",
        "        for stride in strides:\n",
        "            layers.append(block(self.in_planes, planes, stride))\n",
        "            self.in_planes = planes * block.expansion\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.layer1(out)\n",
        "        out = self.layer2(out)\n",
        "        out = self.layer3(out)\n",
        "        out = self.layer4(out)\n",
        "        out = F.avg_pool2d(out, 4)\n",
        "        out = out.view(out.size(0), -1)\n",
        "        out = self.linear(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "def ResNet18():\n",
        "    return ResNet(BasicBlock,[2, 2, 2, 2])\n",
        "\n",
        "\n",
        "def ResNet34():\n",
        "    return ResNet(BasicBlock, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet50():\n",
        "    return ResNet(Bottleneck, [3, 4, 6, 3])\n",
        "\n",
        "\n",
        "def ResNet101():\n",
        "    return ResNet(Bottleneck, [3, 4, 23, 3])\n",
        "\n",
        "\n",
        "def ResNet152():\n",
        "    return ResNet(Bottleneck, [3, 8, 36, 3])\n",
        "\n",
        "\n",
        "def test():\n",
        "    net = ResNet18()\n",
        "    y = net(torch.nn.Parameter((torch.randn(1, 3, 32, 32))))\n",
        "    print(y.size())\n",
        "\n",
        "\n",
        "\n",
        "import argparse\n",
        "import sys\n",
        "\n",
        "# Check if the code is running in a Jupyter Notebook environment\n",
        "try:\n",
        "    import ipykernel\n",
        "    in_notebook = True\n",
        "except ImportError:\n",
        "    in_notebook = False\n",
        "\n",
        "# Only parse arguments if not running in a Jupyter Notebook\n",
        "if not in_notebook:\n",
        "    try:\n",
        "        parser = argparse.ArgumentParser(description='PyTorch CIFAR10 Training')\n",
        "        parser.add_argument('--lr', default=0.1, type=float, help='learning rate')\n",
        "        parser.add_argument('--resume', '-r', action='store_true',\n",
        "                            help='resume from checkpoint')\n",
        "        args = parser.parse_args()\n",
        "    except SystemExit:\n",
        "        # The exception is caught so that the kernel does not exit, allowing you to continue executing cells\n",
        "        pass\n",
        "\n",
        "# Rest of your code here\n",
        "\n",
        "\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(device)\n",
        "best_acc = 0  # best test accuracy\n",
        "start_epoch = 0  # start from epoch 0 or last checkpoint epoch\n",
        "\n",
        "# Data\n",
        "print('==> Preparing data..')\n",
        "transform_train = transforms.Compose([\n",
        "    transforms.RandomCrop(32, padding=4),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010)),\n",
        "])\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=True, download=True, transform=transform_train)\n",
        "trainloader = torch.utils.data.DataLoader(\n",
        "    trainset, batch_size=128, shuffle=True, num_workers=1)                              #CHANGE BATCH SIZE,ORIGNAL 128\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(\n",
        "    root='./data', train=False, download=True, transform=transform_test)\n",
        "testloader = torch.utils.data.DataLoader(\n",
        "    testset, batch_size=128, shuffle=False, num_workers=1)                             #change batch size for test dataset,orignal=100\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat', 'deer',\n",
        "           'dog', 'frog', 'horse', 'ship', 'truck')\n",
        "\n",
        "#net = lora_model\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#resnet defining\n",
        "net = ResNet18()\n",
        "#net = net.to(device)\n",
        "#if device == 'cuda':\n",
        "   #net = torch.nn.DataParallel(net)\n",
        "   #cudnn.benchmark = True\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(net.parameters(), lr=0.1,\n",
        "                      momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)\n",
        "\n",
        "import os\n",
        "import sys\n",
        "import time\n",
        "import math\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.init as init\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_mean_and_std(dataset):\n",
        "    '''Compute the mean and std value of dataset.'''\n",
        "    dataloader = torch.utils.data.DataLoader(dataset, batch_size=1, shuffle=True, num_workers=1)\n",
        "    mean = torch.zeros(3)\n",
        "    std = torch.zeros(3)\n",
        "    print('==> Computing mean and std..')\n",
        "    for inputs, targets in dataloader:\n",
        "        for i in range(3):\n",
        "            mean[i] += inputs[:,i,:,:].mean()\n",
        "            std[i] += inputs[:,i,:,:].std()\n",
        "    mean.div_(len(dataset))\n",
        "    std.div_(len(dataset))\n",
        "    return mean, std\n",
        "\n",
        "def init_params(net):\n",
        "    '''Init layer parameters.'''\n",
        "    for m in net.modules():\n",
        "        if isinstance(m, nn.Conv2d):\n",
        "            init.kaiming_normal(m.weight, mode='fan_out')\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.BatchNorm2d):\n",
        "            init.constant(m.weight, 1)\n",
        "            init.constant(m.bias, 0)\n",
        "        elif isinstance(m, nn.Linear):\n",
        "            init.normal(m.weight, std=1e-3)\n",
        "            if m.bias:\n",
        "                init.constant(m.bias, 0)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "try:\n",
        "    term_size = os.popen('stty size', 'r').read().split()\n",
        "    if len(term_size) == 2:\n",
        "        _, term_width = term_size\n",
        "    else:\n",
        "        term_width = 80  # Default terminal width\n",
        "except ValueError:\n",
        "    term_width = 80  # Default terminal width\n",
        "\n",
        "print(f\"Terminal Width: {term_width}\")\n",
        "\n",
        "\n",
        "\n",
        "import tqdm\n",
        "from tqdm import tqdm\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "9Posowno29aP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c1733ed9-3f5f-495e-b9cf-631680b25958"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Terminal Width: 80\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#training the resnet\n",
        "def train(epoch):\n",
        "    print('\\nEpoch: %d' % epoch)\n",
        "    net.train()\n",
        "    train_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for batch_idx, (inputs, targets) in tqdm(enumerate(trainloader) , unit = \"batch\" , total = len(trainloader)):\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(inputs)\n",
        "        loss = criterion(outputs, targets)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        train_loss += loss.item()\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "        #progress_bar(batch_idx, len(trainloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                    # % (train_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "\n",
        "    print(\"TRAIN  ACCURACY=\", 100.*correct/total )\n",
        "    print(\"loss\" , loss)\n",
        "\n",
        "def test(epoch):\n",
        "    global best_acc\n",
        "    net.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    TOTAL_BAR_LENGTH = 40\n",
        "\n",
        "    with torch.no_grad():\n",
        "         for batch_idx, (inputs, targets) in tqdm(enumerate(trainloader) , unit = \"batch\" , total = len(trainloader)):\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            test_loss += loss.item()\n",
        "            _, predicted = outputs.max(1)\n",
        "            total += targets.size(0)\n",
        "            correct += predicted.eq(targets).sum().item()\n",
        "\n",
        "           # progress_bar(batch_idx, len(testloader), 'Loss: %.3f | Acc: %.3f%% (%d/%d)'\n",
        "                       #  % (test_loss/(batch_idx+1), 100.*correct/total, correct, total))\n",
        "         print(\"batch index=\",batch_idx,\"test_loss/(batch index+1)=\",test_loss/(batch_idx+1),\"accuracy=\", 100.*correct/total,\"correct=\", correct,\"total=\", total)\n",
        "\n",
        "    # Save checkpoint.\n",
        "    acc = 100.*correct/total\n",
        "    if acc > best_acc:\n",
        "        print('Saving..')\n",
        "        state = {\n",
        "            'net': net.state_dict(),\n",
        "            'acc': acc,\n",
        "            'epoch': epoch,\n",
        "            'optimizer': optimizer.state_dict()             ###################################\n",
        "        }\n",
        "        if not os.path.isdir('checkpoint'):\n",
        "            os.mkdir('checkpoint')\n",
        "        torch.save(state, '/ckpt.pth')\n",
        "        best_acc = acc\n",
        "    print(\"TEST ACCURACY=\",acc)\n",
        "\n",
        "#for epoch in range(0, 51):\n",
        "#    train(epoch)\n",
        "#    test(epoch)\n",
        "#    scheduler.step()\n",
        "# Set the starting epoch here\n",
        "start_epoch = 0\n",
        "\n",
        "# Load checkpoint if available\n",
        "if os.path.exists('./ckpt.pth'):\n",
        "    checkpoint = torch.load('./ckpt.pth' , map_location = torch.device('cpu') )\n",
        "    net.load_state_dict(checkpoint['net'], strict = False)\n",
        "    optimizer.load_state_dict(checkpoint['optimizer'])\n",
        "    start_epoch = checkpoint['epoch'] + 1  # Start from the next epoch\n",
        "    print(\"start_epoch\",start_epoch)\n",
        "for epoch in range(start_epoch, 104):  # Set the desired number of epochs\n",
        "    train(epoch)\n",
        "    test(epoch)\n",
        "    scheduler.step()\n",
        "save_path = '/content/drive/MyDrive/model.pth'\n",
        "\n",
        "# Save the model's state dictionary to the specified file\n",
        "torch.save(net.state_dict(), save_path)\n",
        "#torch.save(net.state_dict(), '/content/drive/MyDrive')\n"
      ],
      "metadata": {
        "id": "FNC3hWML3MmB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ae7cf6c9-39f2-4463-8eac-001dc052a1d1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "start_epoch 104\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "CQ0wNlwd3UYM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da1c3c4e-a25f-4578-9977-3b5eb51d4b0a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.chdir('/content/drive/MyDrive')"
      ],
      "metadata": {
        "id": "64r6Z39e4GcA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "state_dict = torch.load(\"/content/drive/MyDrive/model.pth\")\n",
        "net.load_state_dict(state_dict , strict=False)"
      ],
      "metadata": {
        "id": "civ1rB2a5Qeo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2606dd7-9ddd-488a-dc34-e9683929f01f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<All keys matched successfully>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "\n",
        "# Iterate through the model's layers and print detailed information about Conv2d layers\n",
        "for name, layer in net.named_modules():\n",
        "    if isinstance(layer, nn.Conv2d):\n",
        "        print(f\"Conv2d Layer Name: {name}\")\n",
        "        print(f\"Input Channels: {layer.in_channels}\")\n",
        "        print(f\"Output Channels: {layer.out_channels}\")\n",
        "        print(f\"Kernel Size: {layer.kernel_size}\")\n",
        "        print(f\"Stride: {layer.stride}\")\n",
        "        print(f\"Padding: {layer.padding}\")\n",
        "        print(f\"Dilation: {layer.dilation}\")\n",
        "        print(f\"Groups: {layer.groups}\")\n",
        "        print()\n",
        "\n"
      ],
      "metadata": {
        "id": "hUtmy8OuCDrC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_config = []\n",
        "for layer in net.modules():\n",
        "  if isinstance(layer, nn.Conv2d):\n",
        "   target_config.append(layer.weight.shape)\n"
      ],
      "metadata": {
        "id": "Tgx4X_RQGaMd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "strustured pruning\n"
      ],
      "metadata": {
        "id": "8u-kGJMtSp5Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "# Define the target Conv2d layer configuration\n",
        "\n",
        "\n",
        "# Iterate through the model's layers and apply pruning to the similar Conv2d layer\n",
        "for layer in net.modules():\n",
        "    if isinstance(layer, nn.Conv2d) and layer.weight.shape in target_config:\n",
        "\n",
        "        prune.ln_structured(layer, name=\"weight\", amount=0.8, n=float('-inf'), dim=0)\n"
      ],
      "metadata": {
        "id": "3FjBi0eVGPN2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "RUN EITHER ONE OF THE ABOVE AND BELOW ONE"
      ],
      "metadata": {
        "id": "xGeaK1wwJ8J3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "l1 pruning\n"
      ],
      "metadata": {
        "id": "n_u3P86dSsi_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch.nn.utils.prune as prune\n",
        "\n",
        "\n",
        "for name, module in net.named_modules():\n",
        "   if isinstance(module, nn.Conv2d):   #pruning conv2d layers and final linear layers\n",
        "       prune.l1_unstructured(module, name=\"weight\", amount=0.3)   #0.3 is a hyperparameter\n",
        "   if isinstance(module, nn.Linear):   #pruning conv2d layers and final linear layers\n",
        "        prune.l1_unstructured(module, name=\"weight\", amount=0.4)   #0.3 is a hyperparameter\n",
        "\n",
        "\n",
        "prune.l1_unstructured(module, name=\"bias\", amount=3)           #Prune 3 smallest entries in bias by L1 norm"
      ],
      "metadata": {
        "id": "0Eeen1yxC99Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3496c9e3-b4a7-438f-b1a0-7da608569891"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Linear(in_features=512, out_features=10, bias=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "parameter_names = [name for name, _ in net.named_parameters()]\n",
        "print(parameter_names)"
      ],
      "metadata": {
        "id": "X3SZ9Cf6_n4V"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = ResNet18()\n",
        "model_state_dict = net2.state_dict()\n",
        "for key in net.state_dict().keys():\n",
        "    if 'orig' in key:\n",
        "\n",
        "        raw_key = key.split('_')[0]\n",
        "\n",
        "        orig_w_key = raw_key + '_orig'\n",
        "        mask_w_key = raw_key + '_mask'\n",
        "\n",
        "        # Check if orig and mask keys exist in the checkpoint\n",
        "        if orig_w_key not in net.state_dict() or mask_w_key not in net.state_dict():\n",
        "         raise KeyError(f\"Missing orig/mask keys for {raw_key}\")\n",
        "\n",
        "                    # Extract original weight (A) and mask (B)\n",
        "        A = net.state_dict()[orig_w_key]\n",
        "        B = net.state_dict()[ mask_w_key]\n",
        "\n",
        "                    # Check if A and B have compatible shapes\n",
        "        if A.shape != B.shape:\n",
        "          raise ValueError(f\"Shapes of {orig_w_key} and {mask_w_key} do not match\")\n",
        "\n",
        "                  # Perform pointwise multiplication and assign to the original key in the model's state_dict\n",
        "        model_state_dict[raw_key] = A.mul(B)\n",
        "\n",
        "\n",
        "\n",
        "    else:\n",
        "         model_state_dict[key] = net.state_dict()[key]\n",
        "\n"
      ],
      "metadata": {
        "id": "0Gd3BPlXqFK0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2.load_state_dict(model_state_dict,strict = False)"
      ],
      "metadata": {
        "id": "YtbYdy0JC01v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ccc931b2-3b4e-43be-bd18-cec3f7c02a7d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "_IncompatibleKeys(missing_keys=[], unexpected_keys=['conv1.weight_mask', 'layer1.0.conv1.weight_mask', 'layer1.0.conv2.weight_mask', 'layer1.1.conv1.weight_mask', 'layer1.1.conv2.weight_mask', 'layer2.0.conv1.weight_mask', 'layer2.0.conv2.weight_mask', 'layer2.0.shortcut.0.weight_mask', 'layer2.1.conv1.weight_mask', 'layer2.1.conv2.weight_mask', 'layer3.0.conv1.weight_mask', 'layer3.0.conv2.weight_mask', 'layer3.0.shortcut.0.weight_mask', 'layer3.1.conv1.weight_mask', 'layer3.1.conv2.weight_mask', 'layer4.0.conv1.weight_mask', 'layer4.0.conv2.weight_mask', 'layer4.0.shortcut.0.weight_mask', 'layer4.1.conv1.weight_mask', 'layer4.1.conv2.weight_mask', 'linear.weight_mask', 'linear.bias_mask'])"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(model_state_dict['conv1.weight'])\n",
        "print(net2.state_dict()['conv1.weight'])"
      ],
      "metadata": {
        "id": "IWUK7Y5yDJqF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers accelerate evaluate datasets peft -q"
      ],
      "metadata": {
        "id": "YWREMNbcGmtv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "388b9430-55db-4ae4-c7f0-8797e7c2a4c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.9 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.1/7.9 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:03\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.8/7.9 MB\u001b[0m \u001b[31m44.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m90.3 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m66.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m38.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m12.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m493.7/493.7 kB\u001b[0m \u001b[31m55.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m136.0/136.0 kB\u001b[0m \u001b[31m19.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.1/311.1 kB\u001b[0m \u001b[31m38.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m65.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m98.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m19.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m21.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m41.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from peft import LoraConfig, get_peft_model"
      ],
      "metadata": {
        "id": "U8boP3oepjlp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "# Define a regex pattern to match module names containing \"conv1\" or \"conv2\"\n",
        "pattern = re.compile(r'.*(\\.(conv1|conv2))(?!.*dropout).*')\n",
        "\n",
        "# Get all modules in the model that match the pattern\n",
        "target_modules = [name for name, _ in net.named_modules() if pattern.match(name)]\n",
        "\n",
        "# Use the target_modules list in your LoraConfig\n",
        "config = LoraConfig(\n",
        "    r=16,\n",
        "    lora_alpha=16,\n",
        "    target_modules=target_modules,\n",
        "    lora_dropout=0.1,\n",
        "    bias=\"none\",\n",
        "    modules_to_save=[\"linear\",\"classifier\"]\n",
        ")\n",
        "\n"
      ],
      "metadata": {
        "id": "P5EBAU7smnMY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "target_modules"
      ],
      "metadata": {
        "id": "5RGw3Y2PnA8I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def print_trainable_parameters(model):\n",
        "    trainable_params = 0\n",
        "    all_param = 0\n",
        "    for name, param in model.named_parameters():\n",
        "        all_param += param.numel()\n",
        "        if param.requires_grad:\n",
        "            trainable_params += param.numel()\n",
        "    print(\n",
        "\n",
        "          f\"trainable params: {trainable_params} || all params: {all_param} || trainable%: {100 * trainable_params / all_param:.2f}\"\n",
        "    )\n"
      ],
      "metadata": {
        "id": "TJidJTRWBaqb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import peft\n",
        "peft_model = peft.get_peft_model(net2, config)"
      ],
      "metadata": {
        "id": "yTNqX6AxoPWn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#peft_model.load_state_dict(net.state_dict(), strict=False)\n",
        "# Transfer the pre-trained weights to the PEFT model\n",
        "# Print the number of trainable parameters in both models\n",
        "print_trainable_parameters(peft_model)\n",
        "print_trainable_parameters(net)"
      ],
      "metadata": {
        "id": "e53ts7iiDv_t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6cd57b29-674c-498f-c5b0-0dfde04d833e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "trainable params: 555018 || all params: 11728980 || trainable%: 4.73\n",
            "trainable params: 11173962 || all params: 11173962 || trainable%: 100.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **UNLEANRING**"
      ],
      "metadata": {
        "id": "VkYuskfvMF2w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import linear_model, model_selection\n",
        "\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch import optim\n",
        "from torch.utils.data import DataLoader\n",
        "\n",
        "import torchvision\n",
        "from torchvision import transforms\n",
        "from torchvision.utils import make_grid\n",
        "from torchvision.models import resnet18"
      ],
      "metadata": {
        "id": "4bgOLmpAMIa4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# manual random seed is used for dataset partitioning\n",
        "# to ensure reproducible results across runs\n",
        "RNG = torch.Generator().manual_seed(42)"
      ],
      "metadata": {
        "id": "7Nsm9UUMNFWG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# download the forget and retain index split\n",
        "local_path = \"forget_idx.npy\"\n",
        "if not os.path.exists(local_path):\n",
        "    response = requests.get(\n",
        "        \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
        "    )\n",
        "    open(local_path, \"wb\").write(response.content)\n",
        "forget_idx = np.load(local_path)\n",
        "\n",
        "# construct indices of retain from those of the forget set\n",
        "forget_mask = np.zeros(len(trainset.targets), dtype=bool)\n",
        "forget_mask[forget_idx] = True\n",
        "retain_idx = np.arange(forget_mask.size)[~forget_mask]\n",
        "\n",
        "# split train set into a forget and a retain set\n",
        "forget_set = torch.utils.data.Subset(trainset, forget_idx)\n",
        "retain_set = torch.utils.data.Subset(trainset, retain_idx)\n",
        "\n",
        "forget_loader = torch.utils.data.DataLoader(\n",
        "    forget_set, batch_size=128, shuffle=True, num_workers=2\n",
        ")\n",
        "retain_loader = torch.utils.data.DataLoader(\n",
        "    retain_set, batch_size=128, shuffle=True, num_workers=2, generator=RNG\n",
        ")"
      ],
      "metadata": {
        "id": "tCh0-b7HNI9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy(net, loader):\n",
        "    \"\"\"Return accuracy on a dataset given by the data loader.\"\"\"\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "        outputs = net(inputs)\n",
        "        _, predicted = outputs.max(1)\n",
        "        total += targets.size(0)\n",
        "        correct += predicted.eq(targets).sum().item()\n",
        "    return correct / total"
      ],
      "metadata": {
        "id": "HJb9GnMENYLR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def unlearning(net, retain, forget, validation):\n",
        "    \"\"\"Unlearning by fine-tuning.\n",
        "\n",
        "    Fine-tuning is a very simple algorithm that trains using only\n",
        "    the retain set.\n",
        "\n",
        "    Args:\n",
        "      net : nn.Module.\n",
        "        pre-trained model to use as base of unlearning.\n",
        "      retain : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the retain set. This is the subset\n",
        "        of the training set that we don't want to forget.\n",
        "      forget : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the forget set. This is the subset\n",
        "        of the training set that we want to forget. This method doesn't\n",
        "        make use of the forget set.\n",
        "      validation : torch.utils.data.DataLoader.\n",
        "        Dataset loader for access to the validation set. This method doesn't\n",
        "        make use of the validation set.\n",
        "    Returns:\n",
        "      net : updated model\n",
        "    \"\"\"\n",
        "    epochs = 5\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.1, momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    net.train()\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        for i, (inputs, targets) in enumerate(tqdm(retain, desc=f'Epoch {epoch + 1}/{epochs}')):\n",
        "\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    net.eval()\n",
        "    return net"
      ],
      "metadata": {
        "id": "11wjUJ1qNZM4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "fT7qT_Yz8Zty"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "peft_model.to(\"cuda:0\")\n",
        "unlearned_prune_lora_model=unlearning(peft_model, retain_loader, forget_loader, testloader)"
      ],
      "metadata": {
        "id": "Eby4kojsNhpO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90ff3335-3b01-41fc-a2dd-0f3a00de4af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Epoch 1/5: 100%|██████████| 352/352 [00:52<00:00,  6.69it/s]\n",
            "Epoch 2/5: 100%|██████████| 352/352 [00:43<00:00,  8.05it/s]\n",
            "Epoch 3/5: 100%|██████████| 352/352 [00:43<00:00,  8.18it/s]\n",
            "Epoch 4/5: 100%|██████████| 352/352 [00:44<00:00,  7.93it/s]\n",
            "Epoch 5/5: 100%|██████████| 352/352 [00:43<00:00,  8.13it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "dpR3Nqj44cou"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "unlearned_prune_lora_model2 = ResNet18()\n",
        "state_dict_unlearn_prune = torch.load(\"/content/drive/MyDrive/Unlearning_project/unlearned_pruned_lora_model(30%)\")\n",
        "state_dict_unlearn_prune = {key.replace(\"module.\", \"\"): value for key, value in state_dict_unlearn_prune.items()}\n",
        "unlearned_prune_lora_model2.load_state_dict(state_dict_unlearn_prune,strict = False)"
      ],
      "metadata": {
        "id": "v4Mick8qWliX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "file_path = \"/content/drive/MyDrive/Unlearning_project/unlearned_pruned_lora_model(30%)\"\n",
        "#torch.save(unlearnedresnet.state_dict(), file_path)\n",
        "torch.save(unlearned_prune_lora_model.state_dict(), file_path)"
      ],
      "metadata": {
        "id": "us-_raOCOU_l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Retain set accuracy: {100.0 * accuracy(unlearned_prune_lora_model, retain_loader):0.1f}%\")\n",
        "print(f\"Test set accuracy: {100.0 * accuracy(unlearned_prune_lora_model, testloader):0.1f}%\")\n",
        "print(f\"Forget set accuracy: {100.0 * accuracy(unlearned_prune_lora_model, forget_loader):0.1f}%\")"
      ],
      "metadata": {
        "id": "AnH4_uJsOjxc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2a50245b-69db-43a4-b198-664200a2ce4a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Retain set accuracy: 62.4%\n",
            "Test set accuracy: 63.5%\n",
            "Forget set accuracy: 61.0%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "net.to(\"cuda\")\n",
        "#print(f\"Retain set accuracy: {100.0 * accuracy(net, retain_loader):0.1f}%\")\n",
        "#print(f\"Test set accuracy: {100.0 * accuracy(net, testloader):0.1f}%\")"
      ],
      "metadata": {
        "id": "YCQhYdMaS9hi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Evaluation**"
      ],
      "metadata": {
        "id": "8mfVm99-XQz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def simple_mia(sample_loss, members, n_splits=10, random_state=0):\n",
        "    \"\"\"Computes cross-validation score of a membership inference attack.\n",
        "\n",
        "    Args:\n",
        "      sample_loss : array_like of shape (n,).\n",
        "        objective function evaluated on n samples.\n",
        "      members : array_like of shape (n,),\n",
        "        whether a sample was used for training.\n",
        "      n_splits: int\n",
        "        number of splits to use in the cross-validation.\n",
        "    Returns:\n",
        "      scores : array_like of size (n_splits,)\n",
        "    \"\"\"\n",
        "\n",
        "    unique_members = np.unique(members)\n",
        "    if not np.all(unique_members == np.array([0, 1])):\n",
        "        raise ValueError(\"members should only have 0 and 1s\")\n",
        "\n",
        "    attack_model = linear_model.LogisticRegression()\n",
        "    cv = model_selection.StratifiedShuffleSplit(\n",
        "        n_splits=n_splits, random_state=random_state\n",
        "    )\n",
        "    return model_selection.cross_val_score(\n",
        "        attack_model, sample_loss, members, cv=cv, scoring=\"accuracy\"\n",
        "    )"
      ],
      "metadata": {
        "id": "bCAHZYOWXN-u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_losses(net, loader):\n",
        "    \"\"\"Auxiliary function to compute per-sample losses\"\"\"\n",
        "\n",
        "    criterion = nn.CrossEntropyLoss(reduction=\"none\")\n",
        "    all_losses = []\n",
        "\n",
        "    for inputs, targets in loader:\n",
        "        inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "        logits = net(inputs)\n",
        "        losses = criterion(logits, targets).numpy(force=True)\n",
        "        for l in losses:\n",
        "            all_losses.append(l)\n",
        "\n",
        "    return np.array(all_losses)\n",
        "\n",
        "\n",
        "train_losses = compute_losses(unlearned_prune_lora_model, trainloader)\n",
        "test_losses = compute_losses(unlearned_prune_lora_model, testloader)"
      ],
      "metadata": {
        "id": "RiVN0NPibXnn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.title(\"Losses on train and test set (pre-trained model)\")\n",
        "plt.hist(test_losses, density=True, alpha=0.5, bins=50, label=\"Test set\")\n",
        "plt.hist(train_losses, density=True, alpha=0.5, bins=50, label=\"Train set\")\n",
        "plt.xlabel(\"Loss\", fontsize=14)\n",
        "plt.ylabel(\"Frequency\", fontsize=14)\n",
        "plt.xlim((0, np.max(test_losses)))\n",
        "plt.yscale(\"log\")\n",
        "plt.legend(frameon=False, fontsize=14)\n",
        "ax = plt.gca()\n",
        "ax.spines[\"top\"].set_visible(False)\n",
        "ax.spines[\"right\"].set_visible(False)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "lWRYKn0LbXqV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "iD8IMDOnERhj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_forget_losses = compute_losses(unlearned_prune_lora_model, forget_loader)\n",
        "ft_test_losses = compute_losses(unlearned_prune_lora_model, testloader)\n",
        "\n",
        "# make sure we have a balanced dataset for the MIA\n",
        "#assert len(ft_test_losses) == len(ft_forget_losses)\n",
        "\n",
        "ft_samples_mia = np.concatenate((ft_test_losses, ft_forget_losses)).reshape((-1, 1))\n",
        "labels_mia = [0] * len(ft_test_losses) + [1] * len(ft_forget_losses)"
      ],
      "metadata": {
        "id": "Lvty2Gz6bXtB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ft_mia_scores = simple_mia(ft_samples_mia, labels_mia)\n",
        "\n",
        "print(\n",
        "    f\"The MIA has an accuracy of {ft_mia_scores.mean():.3f} on forgotten vs unseen images\"\n",
        ")"
      ],
      "metadata": {
        "id": "bcaE2AribXvt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
        "\n",
        "ax1.set_title(f\"Re-trained model.\")\n",
        "ax1.hist(rt_retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
        "ax1.hist(rt_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
        "\n",
        "ax2.set_title(\n",
        "    f\"Unlearned by fine-tuning our LORA model(r=1) and linear layer as target module\"\n",
        ")\n",
        "ax2.hist(ft_retain_losses, density=True, alpha=0.5, bins=50, label=\"Retain set\")\n",
        "ax2.hist(ft_forget_losses, density=True, alpha=0.5, bins=50, label=\"Forget set\")\n",
        "\n",
        "ax1.set_xlabel(\"Loss\")\n",
        "ax2.set_xlabel(\"Loss\")\n",
        "ax1.set_ylabel(\"Frequency\")\n",
        "ax1.set_yscale(\"log\")\n",
        "ax2.set_yscale(\"log\")\n",
        "ax1.set_xscale(\"log\")\n",
        "ax2.set_xscale(\"log\")\n",
        "ax1.set_xlim((0, np.max(test_losses)))\n",
        "ax2.set_xlim((0, np.max(test_losses)))\n",
        "for ax in (ax1, ax2):\n",
        "    ax.spines[\"top\"].set_visible(False)\n",
        "    ax.spines[\"right\"].set_visible(False)\n",
        "ax1.legend(frameon=False, fontsize=14)\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "1BxmEB1ZElM5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import transformers\n",
        "import accelerate\n",
        "import peft"
      ],
      "metadata": {
        "id": "fgbF4fCdElPo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torchvision.models import resnet18\n",
        "import torch.nn.utils.prune as prune"
      ],
      "metadata": {
        "id": "79jz_pYZa9jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = resnet18(weights=None, num_classes=10)\n",
        "config = LoraConfig(\n",
        "        r=1,\n",
        "        lora_alpha=16,\n",
        "        target_modules=['conv1','conv2','linear'],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        modules_to_save=[\"classifier\"], )\n",
        "lora_model = get_peft_model(net2, config)"
      ],
      "metadata": {
        "id": "9jED44Ylrlll"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 5\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.SGD(lora_model.parameters(), lr=0.001,\n",
        "                          momentum=0.9, weight_decay=5e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=epochs)\n",
        "lora_model.train()\n",
        "for ep in range(epochs):\n",
        "        lora_model.train()\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[\"image\"]\n",
        "            targets = sample[\"age_group\"]\n",
        "            inputs, targets = inputs.to(DEVICE), targets.to(DEVICE)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = lora_model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "lora_model.eval()"
      ],
      "metadata": {
        "id": "nGBi7Gawrz9A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/datasets-2.14.6-py3-none-any.whl"
      ],
      "metadata": {
        "id": "cbKnfvLya56z",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "cea6e5a5-0c02-4062-b7de-6546d7607cc6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/datasets-2.14.6-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (1.23.5)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (9.0.0)\n",
            "Collecting dill<0.3.8,>=0.3.0 (from datasets==2.14.6)\n",
            "  Downloading dill-0.3.7-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.3/115.3 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (3.4.1)\n",
            "Collecting multiprocess (from datasets==2.14.6)\n",
            "  Downloading multiprocess-0.70.15-py310-none-any.whl (134 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m134.8/134.8 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (3.8.6)\n",
            "Collecting huggingface-hub<1.0.0,>=0.14.0 (from datasets==2.14.6)\n",
            "  Downloading huggingface_hub-0.19.0-py3-none-any.whl (311 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.2/311.2 kB\u001b[0m \u001b[31m12.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets==2.14.6) (6.0.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets==2.14.6) (1.3.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0.0,>=0.14.0->datasets==2.14.6) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.6) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->datasets==2.14.6) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.6) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets==2.14.6) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets==2.14.6) (1.16.0)\n",
            "Installing collected packages: dill, multiprocess, huggingface-hub, datasets\n",
            "Successfully installed datasets-2.14.6 dill-0.3.7 huggingface-hub-0.19.0 multiprocess-0.70.15\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/evaluate-0.4.1-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uudaKRl7e55G",
        "outputId": "8800a35d-e8a2-4b76-8cca-900562f5083d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/evaluate-0.4.1-py3-none-any.whl\n",
            "Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (2.14.6)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (1.23.5)\n",
            "Requirement already satisfied: dill in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (1.5.3)\n",
            "Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (2.31.0)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (4.66.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (2023.6.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (0.19.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from evaluate==0.4.1) (23.2)\n",
            "Collecting responses<0.19 (from evaluate==0.4.1)\n",
            "  Downloading responses-0.18.0-py3-none-any.whl (38 kB)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (9.0.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (3.8.6)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from datasets>=2.0.0->evaluate==0.4.1) (6.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub>=0.7.0->evaluate==0.4.1) (4.5.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests>=2.19.0->evaluate==0.4.1) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.1) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->evaluate==0.4.1) (2023.3.post1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (23.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets>=2.0.0->evaluate==0.4.1) (1.3.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->evaluate==0.4.1) (1.16.0)\n",
            "Installing collected packages: responses, evaluate\n",
            "Successfully installed evaluate-0.4.1 responses-0.18.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install /content/peft-0.5.0-py3-none-any.whl"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pB1-cmuxe-Lj",
        "outputId": "1c8c9882-bbc9-4204-ec7e-dc14382735a5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing /content/peft-0.5.0-py3-none-any.whl\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (23.2)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (6.0.1)\n",
            "Requirement already satisfied: torch>=1.13.0 in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (2.1.0+cu118)\n",
            "Collecting transformers (from peft==0.5.0)\n",
            "  Downloading transformers-4.35.0-py3-none-any.whl (7.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.9/7.9 MB\u001b[0m \u001b[31m25.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from peft==0.5.0) (4.66.1)\n",
            "Collecting accelerate (from peft==0.5.0)\n",
            "  Downloading accelerate-0.24.1-py3-none-any.whl (261 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m261.4/261.4 kB\u001b[0m \u001b[31m24.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors (from peft==0.5.0)\n",
            "  Downloading safetensors-0.4.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m31.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.13.1)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (3.1.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (2023.6.0)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.13.0->peft==0.5.0) (2.1.0)\n",
            "Requirement already satisfied: huggingface-hub in /usr/local/lib/python3.10/dist-packages (from accelerate->peft==0.5.0) (0.19.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.5.0) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers->peft==0.5.0) (2.31.0)\n",
            "Collecting tokenizers<0.15,>=0.14 (from transformers->peft==0.5.0)\n",
            "  Downloading tokenizers-0.14.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.8/3.8 MB\u001b[0m \u001b[31m70.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting huggingface-hub (from accelerate->peft==0.5.0)\n",
            "  Downloading huggingface_hub-0.17.3-py3-none-any.whl (295 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m295.0/295.0 kB\u001b[0m \u001b[31m27.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.13.0->peft==0.5.0) (2.1.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.5.0) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.5.0) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.5.0) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers->peft==0.5.0) (2023.7.22)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch>=1.13.0->peft==0.5.0) (1.3.0)\n",
            "Installing collected packages: safetensors, huggingface-hub, tokenizers, accelerate, transformers, peft\n",
            "  Attempting uninstall: huggingface-hub\n",
            "    Found existing installation: huggingface-hub 0.19.0\n",
            "    Uninstalling huggingface-hub-0.19.0:\n",
            "      Successfully uninstalled huggingface-hub-0.19.0\n",
            "Successfully installed accelerate-0.24.1 huggingface-hub-0.17.3 peft-0.5.0 safetensors-0.4.0 tokenizers-0.14.1 transformers-4.35.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import evaluate\n",
        "from peft import LoraConfig, get_peft_model\n",
        "import transformers\n",
        "import accelerate\n",
        "import peft\n",
        "import torch.nn.utils.prune as prune\n",
        "import re"
      ],
      "metadata": {
        "id": "A4dzyICffBiS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# You can replace the below simple unlearning with your own unlearning function.\n",
        "def unlearning(net, retain_loader, forget_loader, val_loader):\n",
        "    \"\"\"Simple unlearning by finetuning.\"\"\"\n",
        "    target_config = []\n",
        "    for layer in net.modules():\n",
        "      if isinstance(layer, nn.Conv2d):\n",
        "        target_config.append(layer.weight.shape)\n",
        "\n",
        "    for layer in net.modules():\n",
        "        if isinstance(layer, nn.Conv2d) and layer.weight.shape in target_config:\n",
        "            prune.ln_structured(layer, name=\"weight\", amount=0.8, n=float('-inf'), dim=0)\n",
        "    net2 = resnet18(weights=None, num_classes=10)\n",
        "    model_state_dict = net2.state_dict()\n",
        "\n",
        "    for key in net.state_dict().keys():\n",
        "        if 'orig' in key:\n",
        "\n",
        "            raw_key = key.split('_')[0]\n",
        "\n",
        "            orig_w_key = raw_key + '_orig'\n",
        "            mask_w_key = raw_key + '_mask'\n",
        "\n",
        "            # Check if orig and mask keys exist in the checkpoint\n",
        "            if orig_w_key not in net.state_dict() or mask_w_key not in net.state_dict():\n",
        "                raise KeyError(f\"Missing orig/mask keys for {raw_key}\")\n",
        "\n",
        "                # Extract original weight (A) and mask (B)\n",
        "            A = net.state_dict()[orig_w_key]\n",
        "            B = net.state_dict()[mask_w_key]\n",
        "\n",
        "            # Check if A and B have compatible shapes\n",
        "            if A.shape != B.shape:\n",
        "                raise ValueError(f\"Shapes of {orig_w_key} and {mask_w_key} do not match\")\n",
        "\n",
        "                # Perform pointwise multiplication and assign to the original key in the model's state_dict\n",
        "            model_state_dict[raw_key] = A.mul(B)\n",
        "\n",
        "\n",
        "        else:\n",
        "           model_state_dict[key] = net.state_dict()[key]\n",
        "\n",
        "\n",
        "    net2.load_state_dict(model_state_dict, strict=False)\n",
        "\n",
        "    #pattern = re.compile(r'.(\\.(conv1|conv2))(?!.*dropout).')\n",
        "    # Get all modules in the model that match the pattern\n",
        "    #target_all_modules = [name for name, _ in net.named_modules() if pattern.match(name)]\n",
        "    #print(target_all_modules)\n",
        "    config = LoraConfig(\n",
        "        r=1,\n",
        "        lora_alpha=16,\n",
        "        target_modules=['conv1','conv2','linear'],\n",
        "        lora_dropout=0.1,\n",
        "        bias=\"none\",\n",
        "        modules_to_save=[\"classifier\"], )\n",
        "    lora_model = get_peft_model(net2, config)\n",
        "    epochs = 10\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    optimizer = optim.SGD(net.parameters(), lr=0.001,\n",
        "                          momentum=0.9, weight_decay=5e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(\n",
        "        optimizer, T_max=epochs)\n",
        "    lora_model.train()\n",
        "    for ep in range(epochs):\n",
        "        lora_model.train()\n",
        "        for sample in retain_loader:\n",
        "            inputs = sample[\"image\"]\n",
        "            targets = sample[\"age_group\"]\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "        scheduler.step()\n",
        "\n",
        "    lora_model.eval()"
      ],
      "metadata": {
        "id": "Hf-GSVbCfZvk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "net2 = resnet18(weights=None, num_classes=10)\n",
        "net2.to(device)\n",
        "net2=unlearning(net,)"
      ],
      "metadata": {
        "id": "eJxkPbqlfjG0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "local_path = \"retrain_weights_resnet18_cifar10.pth\"\n",
        "response = requests.get(\n",
        "        \"https://storage.googleapis.com/unlearning-challenge/\" + local_path\n",
        "    )\n",
        "open(local_path, \"wb\").write(response.content)\n",
        "\n",
        "weights_pretrained = torch.load(local_path, map_location=device)\n",
        "\n",
        "# load model with pre-trained weights\n",
        "rt_model = resnet18(weights=None, num_classes=10)\n",
        "rt_model.load_state_dict(weights_pretrained)\n",
        "rt_model.to(device)\n",
        "rt_model.eval()"
      ],
      "metadata": {
        "id": "JLIxJJ4Cnljs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "os.makedirs('/kaggle/tmp', exist_ok=True)\n",
        "    #retain_loader, forget_loader, validation_loader = get_dataset(64)\n",
        "\n",
        "#retain_loader, forget_loader, validation_loader = get_dataset(64)\n",
        "rt_model = resnet18(weights=None, num_classes=10)\n",
        "rt_model.to(device)\n",
        "for i in range(1):\n",
        "              local_path = \"retrain_weights_resnet18_cifar10.pth\"\n",
        "              response = requests.get(\n",
        "                     \"https://storage.googleapis.com/unlearning-challenge/\" + local_path)\n",
        "              open(local_path, \"wb\").write(response.content)\n",
        "\n",
        "              weights_pretrained = torch.load(local_path, map_location=device)\n",
        "\n",
        "              # load model with pre-trained weights\n",
        "              rt_model = resnet18(weights=None, num_classes=10)\n",
        "              rt_model.load_state_dict(weights_pretrained)\n",
        "              unlearning(rt_model,retain_loader, forget_loader, testloader)\n",
        "              state = rt_model.state_dict()\n",
        "              torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
        "              #net1.load_state_dict(torch.load('/kaggle/input/neurips-2023-machine-unlearning/original_model.pth'))\n",
        "              #torch.save(state, f'/kaggle/tmp/unlearned_checkpoint_{i}.pth')\n",
        "\n",
        "            # Ensure that submission.zip will contain exactly 512 checkpoints\n",
        "            # (if this is not the case, an exception will be thrown).\n",
        "#unlearned_ckpts = os.listdir('/kaggle/tmp')\n",
        "#if len(unlearned_ckpts) != 512:\n",
        "          #raise RuntimeError('Expected exactly 512 checkpoints. The submission will throw an exception otherwise.')\n",
        "\n",
        "#subprocess.run('zip submission.zip /kaggle/tmp/*.pth', shell=True)\n"
      ],
      "metadata": {
        "id": "Ny4ddFjRguUP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "N5D8x3rPhMBC"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}